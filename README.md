# Speech Emotion Recognition using Advanced Machine Learning Models

## Author
- Aditya Sahu

## Introduction
This project leverages the capabilities of Speech Emotion Recognition (SER) systems to analyze and interpret the emotional subtleties embedded in spoken language. Using the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS), this project aims to accurately identify and classify different emotional states expressed by speakers. SER has significant implications for enhancing human-computer interaction, providing richer user experiences, and improving mental health diagnostics.

## Background
The initial research referenced in the paper "Bagged Support Vector Machines for Emotion Recognition from Speech" provides valuable insights into the effectiveness of Support Vector Machines (SVM) for emotion recognition from speech data. However, the complexity and diversity of emotional expressions in human speech suggest that a single model may not capture all nuances effectively.

## Project Objectives
The objective of this project is to extend the work done in the referenced paper by implementing additional machine learning models to enhance emotion recognition capabilities. This involves exploring a combination of advanced neural network architectures that have shown promise in related fields such as natural language processing and audio signal processing.

## Proposed Models
- **Long Short-Term Memory networks (LSTMs)**: Suited for sequence prediction problems because of their ability to remember inputs over long periods, crucial for dealing with the temporal dynamics of speech.
- **CNN-LSTMs**: Combining Convolutional Neural Networks (CNNs) with LSTMs to leverage local feature extraction capabilities of CNNs along with the sequence modeling strengths of LSTMs.
- **Bidirectional LSTM (bi-LSTM) networks layered with CNNs**: This architecture aims to enhance the model's understanding of context by processing data in both forward and reverse directions.

## Reference
- Paper: "Bagged Support Vector Machines for Emotion Recognition from Speech", referred to as CVB.

## License
This project is open-sourced under the [MIT license](LICENSE).

## How to Contribute
Contributions to the project are welcome! Please follow the guidelines outlined in the [CONTRIBUTING.md](CONTRIBUTING.md) file for details on how to submit issues, fork the repo, and create pull requests.

## Contact
For any queries regarding the project, feel free to reach out via GitHub or email at xyz@example.com.
